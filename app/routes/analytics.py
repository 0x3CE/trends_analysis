# app/routes/analytics.py
"""Analytics endpoints for tweet analysis.

* **R√¥le global** : C‚Äôest un module FastAPI qui expose des endpoints REST pour faire des analyses sur les tweets (hashtags, volume horaire, et bient√¥t sentiment).

* **Structure** :

  * Il d√©finit un **router FastAPI** avec le pr√©fixe `/analytics`.
  * Il utilise `Depends(get_db)` pour injecter une session SQLAlchemy dans chaque endpoint.
  * Il d√©l√®gue toute la logique m√©tier √† `AnalyticsService` (donc ce fichier n‚Äôanalyse rien lui-m√™me, il ne fait que router).

* **Endpoints** :

  1. **`/analytics/hashtags`**

     * Retourne les hashtags les plus populaires.
     * Param√®tre `limit` (entre 1 et 100, d√©faut 20).
     * Retourne un dict : `{ "top_hashtags": [...] }`.

  2. **`/analytics/volume_by_hour`**

     * Retourne le nombre de tweets par heure.
     * R√©sultat : `{ "volume_by_hour": [...] }`.

  3. **`/analytics/sentiment`**

     * Pas encore impl√©ment√©.
     * Retourne un **501 Not Implemented** avec une note sur l‚Äôusage futur de biblioth√®ques NLP (TextBlob, VADER, Transformers).

* **Logs et erreurs** :

  * Chaque endpoint logge ce qu‚Äôil g√©n√®re.
  * Si √ßa plante, √ßa remonte un **500 Internal Server Error** clair.

üëâ Bref : ce fichier sert uniquement de **pont entre l‚ÄôAPI (FastAPI) et la logique m√©tier (AnalyticsService)**.

Tu veux m‚Äôenvoyer le fichier **`analytics_service`** juste apr√®s ? Ce sera la pi√®ce ma√Ætresse derri√®re ces endpoints üîë

"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import Dict, Any
import logging

from ..database import get_db
from ..services.analytics_service import AnalyticsService

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/analytics", tags=["analytics"])


@router.get("/hashtags", response_model=Dict[str, Any])
async def get_top_hashtags(
    limit: int = 20, 
    db: Session = Depends(get_db)
) -> Dict[str, Any]:
    """
    Analyse et retourne les hashtags les plus populaires.
    
    Args:
        limit: Nombre maximum de hashtags √† retourner (d√©faut: 20)
        db: Session de base de donn√©es inject√©e
    
    Returns:
        Dict: Dictionnaire contenant les top hashtags avec leurs compteurs
    """
    try:
        # Validation et normalisation du param√®tre
        limit = max(1, min(100, limit))  # Entre 1 et 100
        
        top_hashtags = AnalyticsService.get_top_hashtags(limit=limit, db=db)
        
        logger.info(f"Generated hashtag analysis with {len(top_hashtags)} results")
        return {"top_hashtags": top_hashtags}
        
    except Exception as e:
        logger.error(f"Error during hashtag analysis: {e}")
        raise HTTPException(
            status_code=500,
            detail="Internal server error during hashtag analysis"
        )


@router.get("/volume_by_hour", response_model=Dict[str, Any])
async def get_volume_by_hour(db: Session = Depends(get_db)) -> Dict[str, Any]:
    """
    Analyse le volume de tweets par heure.
    
    Args:
        db: Session de base de donn√©es inject√©e
    
    Returns:
        Dict: Volume de tweets group√© par heure
    """
    try:
        volume_data = AnalyticsService.get_volume_by_hour(db=db)
        
        logger.info(f"Generated volume analysis with {len(volume_data)} time periods")
        return {"volume_by_hour": volume_data}
        
    except Exception as e:
        logger.error(f"Error during volume analysis: {e}")
        raise HTTPException(
            status_code=500,
            detail="Internal server error during volume analysis"
        )


@router.get("/sentiment")
async def get_sentiment_analysis():
    """
    Endpoint placeholder pour l'analyse de sentiment.
    √Ä impl√©menter avec une biblioth√®que de NLP (ex: TextBlob, VADER, transformers).
    """
    raise HTTPException(
        status_code=501,
        detail="Sentiment analysis endpoint not implemented yet. "
               "Consider integrating TextBlob, VADER, or Transformers library."
    )